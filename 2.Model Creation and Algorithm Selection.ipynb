{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model creation and Algorithm Testing\n",
    "\n",
    "In this notebook, I shall used prepared data from the previous notebook to create and train a model.\n",
    "\n",
    "To create the model, I shall check for collinearity (and remove redundant columns) and apply Smote to deal with data imbalance (on the label). \n",
    "\n",
    "The model will be trained using the following algorithms: \n",
    "    * Linear Regression (l1 penalty)\n",
    "    * Linear Regression (l2 penalty)\n",
    "    * Linear Discriminant Analysis \n",
    "    * Gaussian Naive Bayes\n",
    "    * Decision Tree Classifier\n",
    "    * Random Forest Classifier\n",
    "    * SVM classifier\n",
    "    * KNN classifier\n",
    "\n",
    "First, the algorithms will be tested without tunning its parameters\n",
    "\n",
    "Secondly, I will find the best paramaters for some of the above algorithms and re-train the model to see if there was an improvement. \n",
    "\n",
    "Then, I will compare resulst and select the best one.\n",
    "\n",
    "Conclusion and cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 36)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two datasets\n",
    "df=pd.read_csv('dfprepared.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model creation, data balancing and collinearity\n",
    "\n",
    "#### 3.1 Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((655, 35), (282, 35))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(labels=['CreditStatus'], axis=1),\n",
    "    df['CreditStatus'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Smote for data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = X_train\n",
    "train_output = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1: 369, 0: 286})\n",
      "New dataset shape Counter({1: 369, 0: 369})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/featsel/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(train_output)))\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_sample(train_input, train_output)\n",
    "print('New dataset shape {}'.format(Counter(train_output_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Algorithm Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LR classifier (l1) penalty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Accuracy: 0.7375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/featsel/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Given smote, we have to do a little adjustment\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "logreg = LogisticRegression(fit_intercept=True, penalty='l1')\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "logregprediction=logreg.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Lasso Accuracy:\",metrics.accuracy_score(logregprediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LR Classifier (l2) penalty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Accuracy: 0.7375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/featsel/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Given smote, we have to do a little adjustment\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "logreg2 = LogisticRegression(fit_intercept=True, penalty='l2')\n",
    "logreg2.fit(X_train, Y_train)\n",
    "logreg2prediction=logreg2.predict(X_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Lasso Accuracy:\",metrics.accuracy_score(logregprediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Discriminant Analysis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Accuracy: 0.7269503546099291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/featsel/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/featsel/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "#Given smote, we have to do a little adjustment\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, Y_train)\n",
    "lda.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "lda_prediction=lda.predict(X_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"LDA Accuracy:\",metrics.accuracy_score(lda_prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Accuracy: 0.7198581560283688\n"
     ]
    }
   ],
   "source": [
    "#Given smote, we have to do a little adjustment\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "gnbprediction=logreg2.predict(X_test)\n",
    "print(\"GNB Accuracy:\",metrics.accuracy_score(gnbprediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.7375886524822695\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#making the instance\n",
    "dtc= DecisionTreeClassifier(random_state=1234)\n",
    "#learning\n",
    "dtc.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "dtcprediction=dtc.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Decision Tree Classifier Accuracy:\",metrics.accuracy_score(dtcprediction,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/featsel/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.8120567375886525\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#making the instance\n",
    "rfc=RandomForestClassifier(n_jobs=-1,random_state=123)\n",
    "#learning\n",
    "rfc.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "rfcprediction=rfc.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Random Forest Classifier Accuracy:\",metrics.accuracy_score(rfcprediction,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier: 0.7163120567375887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/featsel/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "from sklearn import svm\n",
    "#making the instance\n",
    "svc = svm.SVC(random_state=123)\n",
    "#learning\n",
    "svc.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "svcprediction=svc.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy of SVM classifier:\",metrics.accuracy_score(svcprediction,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-NearestNeighbours Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier Accuracy: 0.7056737588652482\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#making the instance\n",
    "knn = KNeighborsClassifier()\n",
    "#learning\n",
    "knn.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "knnprediction=knn.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"KNN classifier Accuracy:\",metrics.accuracy_score(knnprediction,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB classifier Accuracy: 0.7056737588652482\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "import xgboost as xgb\n",
    "\n",
    "#making the instance\n",
    "xgb = xgb.XGBClassifier()\n",
    "#learning\n",
    "xgb.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "xgbprediction=knn.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"XGB classifier Accuracy:\",metrics.accuracy_score(xgbprediction,y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier Accuracy: 0.7056737588652482\n",
      "Random Forest Classifier Accuracy: 0.8120567375886525\n",
      "Accuracy of SVM classifier: 0.7163120567375887\n",
      "Decision Tree Classifier Accuracy: 0.7375886524822695\n",
      "GNB Accuracy: 0.7198581560283688\n",
      "LDA Accuracy: 0.7269503546099291\n",
      "Ridge Accuracy: 0.7198581560283688\n",
      "Lasso Accuracy: 0.7375886524822695\n",
      "XGB classifier Accuracy: 0.7056737588652482\n"
     ]
    }
   ],
   "source": [
    "### 6. Compare models (baseline vs tuned models)\n",
    "print(\"KNN classifier Accuracy:\",metrics.accuracy_score(knnprediction,y_test))\n",
    "print(\"Random Forest Classifier Accuracy:\",metrics.accuracy_score(rfcprediction,y_test))\n",
    "print(\"Accuracy of SVM classifier:\",metrics.accuracy_score(svcprediction,y_test))\n",
    "print(\"Decision Tree Classifier Accuracy:\",metrics.accuracy_score(dtcprediction,y_test))\n",
    "print(\"GNB Accuracy:\",metrics.accuracy_score(gnbprediction,y_test))\n",
    "print(\"LDA Accuracy:\",metrics.accuracy_score(lda_prediction,y_test))\n",
    "print(\"Ridge Accuracy:\",metrics.accuracy_score(logreg2prediction,y_test))\n",
    "print(\"Lasso Accuracy:\",metrics.accuracy_score(logregprediction,y_test))\n",
    "print(\"XGB classifier Accuracy:\",metrics.accuracy_score(xgbprediction,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion and Cross Validation\n",
    "\n",
    "Random Forest Classifier as the best classifier.\n",
    "\n",
    "Now in the next notebook, I shall try to improve it by:\n",
    "- Selecting the best feature set\n",
    "- Tuning its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 76.79%\n",
      "Dev Set score: 77.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/featsel/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation \n",
    "print(\"Cross Validation Score: {:.2%}\".format(np.mean(cross_val_score(rfc, X_train, Y_train, cv=10))))\n",
    "lda.fit(X_train, Y_train)\n",
    "print(\"Dev Set score: {:.2%}\".format(rfc.score(X_dev, Y_dev)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
