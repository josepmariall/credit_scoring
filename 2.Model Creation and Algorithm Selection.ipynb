{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model creation and Algorithm Testing\n",
    "\n",
    "In this notebook, I shall used prepared data from the previous notebook to create and train a model.\n",
    "\n",
    "To create the model, I shall check for collinearity (and remove redundant columns) and apply Smote to deal with data imbalance (on the label). \n",
    "\n",
    "The model will be trained using the following algorithms: \n",
    "    * Linear Regression (l1 penalty)\n",
    "    * Linear Regression (l2 penalty)\n",
    "    * Linear Discriminant Analysis \n",
    "    * Gaussian Naive Bayes\n",
    "    * Decision Tree Classifier\n",
    "    * Random Forest Classifier\n",
    "    * SVM classifier\n",
    "\n",
    "First, the algorithms will be tested without tunning its parameters\n",
    "\n",
    "Secondly, I will find the best paramaters for some of the above algorithms and re-train the model to see if there was an improvement. \n",
    "\n",
    "Then, I will compare resulst and select the best one.\n",
    "\n",
    "Conclusion and cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from numpy import loadtxt\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(807, 22)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two datasets\n",
    "X_train=pd.read_csv('X_train.csv',sep= ',')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=pd.read_csv('X_test.csv',sep= ',')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(807, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two datasets\n",
    "y_train=pd.read_csv('y_train.csv',sep= ',')\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two datasets\n",
    "y_test=pd.read_csv('y_test.csv',sep= ',')\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data balancing and collinearity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Smote for data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = X_train\n",
    "train_output = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'CreditStatus': 1})\n",
      "New dataset shape Counter({0: 439, 1: 439})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(train_output)))\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_sample(train_input, train_output)\n",
    "print('New dataset shape {}'.format(Counter(train_output_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Algorithm Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LR classifier (l1) penalty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Accuracy: 0.7622377622377622\n"
     ]
    }
   ],
   "source": [
    "#Given smote, we have to do a little adjustment\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=123)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "logreg = LogisticRegression(fit_intercept=True, penalty='l1')\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "logregprediction=logreg.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Lasso Accuracy:\",metrics.accuracy_score(logregprediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LR Classifier (l2) penalty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Accuracy: 0.7622377622377622\n"
     ]
    }
   ],
   "source": [
    "#Given smote, we have to do a little adjustment\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "logreg2 = LogisticRegression(fit_intercept=True, penalty='l2')\n",
    "logreg2.fit(X_train, Y_train)\n",
    "logreg2prediction=logreg2.predict(X_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Lasso Accuracy:\",metrics.accuracy_score(logregprediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Discriminant Analysis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Accuracy: 0.7762237762237763\n"
     ]
    }
   ],
   "source": [
    "#Given smote, we have to do a little adjustment\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, Y_train)\n",
    "lda.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "lda_prediction=lda.predict(X_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"LDA Accuracy:\",metrics.accuracy_score(lda_prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Accuracy: 0.7622377622377622\n"
     ]
    }
   ],
   "source": [
    "#Given smote, we have to do a little adjustment\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "gnbprediction=logreg2.predict(X_test)\n",
    "print(\"GNB Accuracy:\",metrics.accuracy_score(gnbprediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.6993006993006993\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#making the instance\n",
    "dtc= DecisionTreeClassifier(random_state=1234)\n",
    "#learning\n",
    "dtc.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "dtcprediction=dtc.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Decision Tree Classifier Accuracy:\",metrics.accuracy_score(dtcprediction,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.7972027972027972\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#making the instance\n",
    "rfc=RandomForestClassifier(n_jobs=-1,random_state=123)\n",
    "#learning\n",
    "rfc.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "rfcprediction=rfc.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Random Forest Classifier Accuracy:\",metrics.accuracy_score(rfcprediction,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier: 0.7412587412587412\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "from sklearn import svm\n",
    "#making the instance\n",
    "svc = svm.SVC(random_state=123)\n",
    "#learning\n",
    "svc.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "svcprediction=svc.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy of SVM classifier:\",metrics.accuracy_score(svcprediction,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-NearestNeighbours Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier Accuracy: 0.7622377622377622\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "#importing module\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#making the instance\n",
    "knn = KNeighborsClassifier()\n",
    "#learning\n",
    "knn.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "knnprediction=knn.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"KNN classifier Accuracy:\",metrics.accuracy_score(knnprediction,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ada Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN classifier Accuracy: 0.8041958041958042\n"
     ]
    }
   ],
   "source": [
    "#remember becaus of the new data after imbalance adjustment, we use the following\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n",
    "\n",
    "ada_model = AdaBoostClassifier(n_estimators=200, random_state=44)\n",
    "\n",
    "\n",
    "#learning\n",
    "ada_model.fit(X_train,Y_train)\n",
    "#Prediction\n",
    "ada_modelprediction=ada_model.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"NN classifier Accuracy:\",metrics.accuracy_score(ada_modelprediction,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier Accuracy: 0.7622377622377622\n",
      "Random Forest Classifier Accuracy: 0.7972027972027972\n",
      "Accuracy of SVM classifier: 0.7412587412587412\n",
      "Decision Tree Classifier Accuracy: 0.6993006993006993\n",
      "GNB Accuracy: 0.7622377622377622\n",
      "LDA Accuracy: 0.7762237762237763\n",
      "Ridge Accuracy: 0.7622377622377622\n",
      "Lasso Accuracy: 0.7622377622377622\n"
     ]
    }
   ],
   "source": [
    "### 6. Compare models (baseline vs tuned models)\n",
    "print(\"KNN classifier Accuracy:\",metrics.accuracy_score(knnprediction,y_test))\n",
    "print(\"Random Forest Classifier Accuracy:\",metrics.accuracy_score(rfcprediction,y_test))\n",
    "print(\"Accuracy of SVM classifier:\",metrics.accuracy_score(svcprediction,y_test))\n",
    "print(\"Decision Tree Classifier Accuracy:\",metrics.accuracy_score(dtcprediction,y_test))\n",
    "print(\"GNB Accuracy:\",metrics.accuracy_score(gnbprediction,y_test))\n",
    "print(\"LDA Accuracy:\",metrics.accuracy_score(lda_prediction,y_test))\n",
    "print(\"Ridge Accuracy:\",metrics.accuracy_score(logreg2prediction,y_test))\n",
    "print(\"Lasso Accuracy:\",metrics.accuracy_score(logregprediction,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion and Cross Validation\n",
    "\n",
    "Sector Random Forest Classifier as the best classifier.\n",
    "\n",
    "Now in the next notebook, I shall try to improve it by:\n",
    "- Selecting the best feature set\n",
    "- Tuning its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 80.49%\n",
      "Dev Set score: 83.52%\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation \n",
    "print(\"Cross Validation Score: {:.2%}\".format(np.mean(cross_val_score(rfc, X_train, Y_train, cv=10))))\n",
    "lda.fit(X_train, Y_train)\n",
    "print(\"Dev Set score: {:.2%}\".format(rfc.score(X_dev, Y_dev)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
